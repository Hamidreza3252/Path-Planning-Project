{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Work in progress...) \n",
    "\n",
    "# A Summary of Kalman Filter Process  \n",
    "\n",
    "- I have prepared this repository to summarize Kalman filter processes based on following resources: \n",
    "\n",
    "  - [Lectures in the Kalman Filter](http://www.ilectureonline.com/lectures/subject/SPECIAL%20TOPICS/26/190)\n",
    "  - Udacity Self-Driving car courses \n",
    "  - Some other online reading materials "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 1. Kalman Filter with Cartesian States Measurements  \n",
    "\n",
    "In this section, I summarise Kalman Filter basics using Cartesian states update equations. Examples of this section include laser-sensors based measurements. \n",
    "\n",
    "\n",
    "## 1-1. Kalman Filter Basics   \n",
    "\n",
    "Kalman filter is an iterative mathematical process that uses a set of equations and consecutive data inputs to quickly estimate the true value, position, velocity, etc. of the object being measured, when the measured values contain unpredicted or random error, uncertainty, or variation. \n",
    "\n",
    "In this process, we start with an initial estimate of a measurement, with certain amount of error or uncertainty. As we receive more data inputs and we go through this iterative process, the Kalman Filterâ€™s estimated value narrows down close to the actual value of the measurement. \n",
    "\n",
    "There are three main calculations that need to be done iteratively: \n",
    "1. Calculate the Kalman Gain \n",
    "2. Calculate the current estimate \n",
    "3. Calculate the new error (uncertainty) in the new estimate \n",
    "\n",
    "An overview of the process for Cartesian states measurements is shown below and the details - in multi-dimensional motion models - are explained as follows.  \n",
    "\n",
    "<a href=\"Images/KF-02.jpg\" target=\"_blank\"><img src=\"Images/KF-02.jpg\" \n",
    "alt=\"Kalman Filter Overview\" width=\"90%\" height=\"90%\" border=\"10\" /></a>  \n",
    "\n",
    "\n",
    "## 1-2. Start with the Initial State Matrix  \n",
    "\n",
    "The initial state ($k=0$) of the Kalman filter process contains two components: the state matrix (e.g. position and velocity) and a process covariance matrix (error/uncertainty in the estimate or process). That means that the Kalman filter process inherently accounts for the process error, to keep track of the errors and estimate them in each iteration. The initial and the current state matrices are defined by the equations below. \n",
    "\n",
    "\\begin{equation*}\n",
    "\\begin{bmatrix}\n",
    "X_{0} \\\\\n",
    "P_{0} \n",
    "\\end{bmatrix}\n",
    "\\: \\:\n",
    "\\text{Initial State,}\n",
    "\\: \\:\n",
    "\\begin{bmatrix}\n",
    "X_{k-1} \\\\\n",
    "P_{k-1} \n",
    "\\end{bmatrix}\n",
    "\\: \\:\n",
    "\\text{Previous State} \\: (k-1)\n",
    "\\end{equation*}\n",
    "\n",
    "An example of state matrix $X$ is position and velocity components of an object in 2D space: \n",
    "\n",
    "\\begin{equation*}\n",
    "X = \n",
    "\\begin{bmatrix}\n",
    "x \\\\\n",
    "y \\\\ \n",
    "\\dot {x} \\\\\n",
    "\\dot {y} \\\\ \n",
    "\\end{bmatrix}\n",
    "\\: \\:\n",
    "\\text{or (in another format)    }\n",
    "X = \n",
    "\\begin{bmatrix}\n",
    "x \\\\\n",
    "\\dot {x} \\\\\n",
    "y \\\\ \n",
    "\\dot {y} \\\\ \n",
    "\\end{bmatrix}\n",
    "\\end{equation*}\n",
    "\n",
    "In this process, we also have to take into account the parameter $\\Delta t$, time associated with one cycle. \n",
    "\n",
    "<a id=\"section_1-3\"></a>\n",
    "\n",
    "## 1-3. Predict New State from the Previous State  \n",
    "\n",
    "The state matrix is updated using the following formula: \n",
    "\n",
    "\\begin{equation*}\n",
    "\\begin{bmatrix}\n",
    "X_{k} \\\\\n",
    "P_{k} \n",
    "\\end{bmatrix}=\n",
    "\\begin{bmatrix}\n",
    "F X_{k-1} + B u_{k} + w_{k} \\\\\n",
    "F P_{k-1} F^{T} + Q_{k} \n",
    "\\end{bmatrix}\n",
    "\\qquad\\qquad\n",
    "\\text{Eq. (1-1)}\n",
    "\\end{equation*}\n",
    "\n",
    "where:  \n",
    "\n",
    "- **Control variables matrix**, $u_{k}$, can be taken into account in case we have more detailed information on the physics of the problem, and any stimulating parameter that can impact the status of the states. The more accurate physical model we have from the system, the more accurate (less erratic or uncertain) prediction we can make about the states of the system.  \n",
    "\n",
    "- **Predicted state noise matrix**, $w_{k}$, can take care of any noise present in the prediction process as well as the errors caused due to deviation from initial assumptions of the model. For example, if we assume that the velocity of a car is constant within a short period of time $\\Delta t$, the error due to deviation from this assumption can be consideerd as noise. Usually in motion models, $w_{k}$ is considered as nornal distribution with mean zero. However, its variance is taken into account in the 2nd part of Eq. (1-1).  \n",
    "\n",
    "- **Adaption or state transition matrices**, $F$ and $B$, are introduced just to map inputs to the new state matrix.  \n",
    "\n",
    "- **Process noise covariance matrix**, $Q_{k}$, is present in updating the process variation to calculate the current state of **process covariance matrix**. The reason why we need to incorporate $Q$ into the process is dsicussed below in section [1-4](#section_1-4).  \n",
    "\n",
    "### 1-3-1. Adaptation (State Transition) Matrix $F$   \n",
    "\n",
    "Consider a two-dimensional motion (position and velocity tracking) with state matrix $X=[x, \\dot {x}, y, \\dot {y}]$. Assuming constant velocity within the time increment of $\\Delta t$, the adaptation matrix $F$ will look like as follows:  \n",
    "\n",
    "\\begin{equation*}\n",
    "F = \n",
    "\\begin{bmatrix}\n",
    "1 & \\Delta t & 0 & 0 \\\\\n",
    "0 & 1 & 0 & 0 \\\\ \n",
    "0 & 0 & 1 & \\Delta t \\\\\n",
    "0 & 0 & 0 & 1 \\\\ \n",
    "\\end{bmatrix}\n",
    "\\qquad\\qquad\n",
    "\\text{Eq. (1-2)}\n",
    "\\end{equation*}\n",
    "\n",
    "Likewise, if we rewrite the state matrix as $X=[x, y, \\dot {x}, \\dot {y}]$, the adaptation matrix $A$ will have the following form:  \n",
    "\n",
    "\\begin{equation*}\n",
    "F = \n",
    "\\begin{bmatrix}\n",
    "1 & 0 & \\Delta t & 0 \\\\\n",
    "0 & 1 & 0 & \\Delta t \\\\ \n",
    "0 & 0 & 1 & 0 \\\\\n",
    "0 & 0 & 0 & 1 \\\\ \n",
    "\\end{bmatrix}\n",
    "\\qquad\\qquad\n",
    "\\text{Eq. (1-3)}\n",
    "\\end{equation*}\n",
    "\n",
    "In Kalman filter process, the term $F X_{k-1}$ accounts for incremental changes in position and velocity, $[x, \\dot {x}, y, \\dot {y}]$, assuming constant velocity for each time increment.  \n",
    "\n",
    "If we have enough knowledge about the the motion model of our system, we may be able to explicitly incorporate it in the prediction step through the term $B u$. For example, in case of a two-dimensional motion model with the form of Eq. (1-3), the term $B u$ will be: \n",
    "\n",
    "\\begin{equation*}\n",
    "\\begin{bmatrix}\n",
    "\\frac{1}{2} \\Delta t^2 & 0 \\\\\n",
    "\\Delta t & 0\\\\\n",
    "0 & \\frac{1}{2} \\Delta t^2 \\\\ \n",
    "0 & \\Delta t \\\\ \n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "a_x \\\\\n",
    "a_y \\\\ \n",
    "\\end{bmatrix}\n",
    "\\qquad\\qquad\n",
    "\\text{Eq. (1-4)}\n",
    "\\end{equation*}\n",
    "\n",
    "However, in most of the problems that we would like to model, we do not have enough knowledge on the stimulus of the system. As a workaround in Kalman Filter process, we can assume that within the time increment of $\\Delta t$, velocity is constant, i.e. acceleration is zero, or $B u = 0$. Instead, it is introduced as a noise vector, $\\nu$, with mean zero and covariance matrix $Q$, as follows:  \n",
    "\n",
    "\\begin{equation*}\n",
    "\\nu = \n",
    "\\begin{bmatrix}\n",
    "\\nu_{x} \\\\\n",
    "\\nu_{y} \\\\\n",
    "\\nu_{v_{x}} \\\\\n",
    "\\nu_{v_{y}} \\\\\n",
    "\\end{bmatrix}\n",
    "\\: =\n",
    "\\:\n",
    "N \\left( 0, Q \\right)\n",
    "\\end{equation*}\n",
    "\n",
    "The covariance matrix $Q$ is called the **process variation** or **state covariance matrix**, which is discussed below in the next section.  \n",
    "\n",
    "### 1-3-2. Process Variation   \n",
    "\n",
    "The second part of state-update equation, Eq. (1-1), is about updating the **process variation** or **state covariance matrix**, $P$.  \n",
    "\n",
    "- **Why do we need to account for the state covariance matrix in the prediction process?**  \n",
    "  The motion model, which we usually use, have several approximations and simplifications. Therefore, the prediction process will compound of some degree of uncertainty or error, which we have to calculate and include it into the motion model.   \n",
    "  \n",
    "- **How does it impact the Klman Filter process?**  \n",
    "  In estimation of the Kalman Gain. Kalman filter uses this error, $P$, (together with **measurement covariance matrix**, $R$, as discussed further below), to decide on how much of prediction and measurement should go in estimating the current state of the system.  \n",
    "  \n",
    "- **Where is it usually initiated from?**  \n",
    "  The **process variation** usually starts from the initial noise or uncertainty, which is called **process noise covariance matrix**, as indicated as $Q$ in Eq. (1-1). This noise covariance matrix, $Q$, can compound of any uncertainty in the process of predicting the states (with reasonable expectation of the error in the process).  \n",
    "\n",
    "> Before we proceed with derivation of matrix $Q$ for our 2-D motion model example, let us take a closer look at the meaning of Covariance Matrices, in general and in the process of Kalman Filter.  \n",
    "\n",
    ">**Standard Dviation vs Variance**:  \n",
    "\n",
    ">Standard deviation of a set of scattered data points, $\\sigma_{x}$, is simply squared root of variance, $\\sigma_{x}^2$. But since the elements of a covariance matrix are vaiances, it may be helpful to quickly compare the meaning of Standard Dviation vs Variance.  \n",
    "\n",
    ">- **Meaning:**  \n",
    "  Standard deviation is a measure of dispersion of observations within a data set. For example, Standard deviation means that about $2/3$ of the values reside within $\\bar {x} \\pm \\sigma_{x}$;  \n",
    "  Variance is a numerical value that describes the variability of observations from its arithmetic mean.  \n",
    "\n",
    ">- **Indication:**  \n",
    "  Standard deviation indicates how much observations of a data set differs from its mean;  \n",
    "  Variance indicates how far individuals in a group are spread out.\t \n",
    "  \n",
    ">- **Unit:**  \n",
    "  Standard deviation has same units as the values in the set of data;  \n",
    "  Variance has Squared units, therefore, it is no longer in the same unit of measurement as the original data.  \n",
    "\n",
    ">Subjectively, Standard deviation is more preferable to use rathen than variance. However, expressing the equations in matrix form will lead to appearance of variance at the elements of covariance matrix. The diagonal elmenets are the same as squared of standard deviation, i.e. $\\sigma_{x}^2$, $\\sigma_{y}^2$, etc. However, the off-diagonal elements will reveal additional information about the relative spread of the data across two axes. This can be explained more clearly by the following equations:  \n",
    "\n",
    ">\\begin{equation*}\n",
    "\\sigma_{x}^2 = \n",
    "\\frac{1}{N}\n",
    "\\sum {\\left( x_{i} - \\bar {x} \\right)^2} \n",
    "\\: \\:\n",
    "\\text{, variance along x-direction}\n",
    "\\qquad\\qquad\n",
    "\\text{Eq. (1-5)}\n",
    "\\end{equation*}\n",
    "\n",
    ">\\begin{equation*}\n",
    "\\sigma_{y}^2 = \n",
    "\\frac{1}{N}\n",
    "\\sum {\\left( y_{i} - \\bar {y} \\right)^2} \n",
    "\\: \\:\n",
    "\\text{, variance along y-direction}\n",
    "\\qquad\\qquad\n",
    "\\text{Eq. (1-6)}\n",
    "\\end{equation*}\n",
    "\n",
    ">\\begin{equation*}\n",
    "\\sigma_x \\sigma_y = \n",
    "\\frac{1}{N} \\sum {\\left( x_{i} - \\bar {x} \\right) \\left( y_{i} - \\bar {y} \\right)}\n",
    "\\: \\:\n",
    "\\text{, covariance}\n",
    "\\qquad\\qquad\n",
    "\\text{Eq. (1-7)}\n",
    "\\end{equation*}\n",
    "\n",
    ">The covariance $\\sigma_x \\sigma_y$ ($=\\sigma_y \\sigma_x$) takes into account the spread of the data sets across length and width axes, representing the **relative variance**. Another point to hightlight here is that a positive covariance value means direct relationship between two variations, and vice-versa, negative covariance indicates inverse relationship (zero means no dependency).  \n",
    "\n",
    "\n",
    "\\begin{equation*}\n",
    "\\nu = \n",
    "\\begin{bmatrix}\n",
    "\\nu_{x} \\\\\n",
    "\\nu_{y} \\\\\n",
    "\\nu_{v_{x}} \\\\\n",
    "\\nu_{v_{y}} \\\\\n",
    "\\end{bmatrix}\n",
    "\\: =\n",
    "\\:\n",
    "\\begin{bmatrix}\n",
    "\\frac{1}{2} a_{x} \\Delta t^2 \\\\\n",
    "\\frac{1}{2} a_{y} \\Delta t^2 \\\\\n",
    "a_{x} \\Delta t \\\\\n",
    "a_{y} \\Delta t \\\\\n",
    "\\end{bmatrix}\n",
    "\\:\n",
    "\\sim N \\left( 0, Q \\right) \n",
    "\\qquad\\qquad\n",
    "\\text{Eq. (1-8)}\n",
    "\\end{equation*}\n",
    "\n",
    "Now the objective is to find out the covariance matrix, $Q$, as follows: \n",
    "\n",
    "\\begin{equation*}\n",
    "\\nu = \n",
    "\\begin{bmatrix}\n",
    "\\frac{1}{2} a_{x} \\Delta t^2 \\\\\n",
    "\\frac{1}{2} a_{y} \\Delta t^2 \\\\\n",
    "a_{x} \\Delta t \\\\\n",
    "a_{y} \\Delta t \\\\\n",
    "\\end{bmatrix}\n",
    "\\: =\n",
    "\\begin{bmatrix}\n",
    "\\frac{\\Delta t^2}{2} & 0 \\\\\n",
    "0 & \\frac{\\Delta t^2}{2} \\\\\n",
    "\\Delta t & 0\\\\\n",
    "0 & \\Delta t \\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "a_{x} \\\\\n",
    "a_{y} \\\\\n",
    "\\end{bmatrix}\n",
    "\\:=\n",
    "Ga\n",
    "\\end{equation*}\n",
    "\n",
    "where $a$ is random acceleration vector. Therefore:\n",
    "\n",
    "\\begin{equation*}\n",
    "Q = E\\left[\\nu \\nu^T \\right] = G E\\left[a a^T \\right] G^T = G\n",
    "\\begin{bmatrix}\n",
    "\\sigma^2_{a_{x}} & \\sigma_{a_{xy}} \\\\\n",
    "\\sigma_{a_{yx}} & \\sigma^2_{a_{y}} \\\\\n",
    "\\end{bmatrix}\n",
    "G^T\n",
    "\\qquad\\qquad\n",
    "\\text{Eq. (1-9)}\n",
    "\\end{equation*}\n",
    "\n",
    "As explained above, the off-diagonal elements of indicate the relative variance. In our motion model, we assume that $a_{x}$ and $a_{y}$ are uncorrelated noise processes, therefore: \n",
    "\n",
    "\\begin{equation*}\n",
    "Q = G\n",
    "\\:\n",
    "\\begin{bmatrix}\n",
    "\\sigma^2_{a_{x}} & 0 \\\\\n",
    "0 & \\sigma^2_{a_{y}} \\\\\n",
    "\\end{bmatrix}\n",
    "\\:\n",
    "G^T\n",
    "\\: =\n",
    "\\begin{bmatrix}\n",
    "\\frac{1}{4} {\\Delta t}^4 \\sigma^2_{a_x} & 0 & \\frac{1}{2} {\\Delta t}^3 \\sigma^2_{a_x} & 0 \\\\\n",
    "0 & \\frac{1}{4} {\\Delta t}^4 \\sigma^2_{a_y} & 0 & \\frac{1}{2} {\\Delta t}^3 \\sigma^2_{a_y} \\\\\n",
    "\\frac{1}{2} {\\Delta t}^3 \\sigma^2_{a_x} & 0 & {\\Delta t}^2 \\sigma^2_{a_x} & 0 \\\\\n",
    "0 & \\frac{1}{2} {\\Delta t}^3 \\sigma^2_{a_y} & 0 & {\\Delta t}^2 \\sigma^2_{a_y} \\\\\n",
    "\\end{bmatrix}\n",
    "\\qquad\\qquad\n",
    "\\text{Eq. (1-10)}\n",
    "\\end{equation*}\n",
    "\n",
    "#### 1-3-2-1. Original / Initial Error Estimate\n",
    "Now that we have discussed about the definition of covariance matrix, let us see how it is used to the inital calculate process variaions, $P_{k-1}$ in Kalman filter process. To do so, let us take an 2-dimensional example of linear motion with the states $[x, \\dot {x}]$ or simply $[x, v_{x}]$, with known initial errors of $\\Delta x$ and $\\Delta v_{x}$. Therefore, the initial process variaions matrix will be: \n",
    "\n",
    "\\begin{equation*}\n",
    "P_{0} = \n",
    "\\begin{bmatrix}\n",
    "{\\Delta x}^2 & \\Delta x \\Delta v_{x} \\\\\n",
    "\\Delta v_{x} \\Delta x & {\\Delta v_{x}}^2 \\\\\n",
    "\\end{bmatrix}\n",
    "\\end{equation*}\n",
    "\n",
    "However, to simplify it, we do not often know the relationship between the change in $x$ and $v_{x}$ adn therefore we do not need off-diagonal terms and we can set them to zero as follows: \n",
    "\n",
    "\\begin{equation*}\n",
    "P_{0} = \n",
    "\\begin{bmatrix}\n",
    "{\\Delta x}^2 & 0 \\\\\n",
    "0 & {\\Delta v_{x}}^2 \\\\\n",
    "\\end{bmatrix}\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "<a id=\"section_1-4\"></a>\n",
    "## 1-4. Estimate Actual Measured Value  \n",
    "\n",
    "Once we have done the theoretical prediction, we are ready to incorporate the actual measured value as follows: \n",
    "\n",
    "\\begin{equation*}\n",
    "\\begin{bmatrix}\n",
    "Z_{k_m} + r\\\\\n",
    "R \n",
    "\\end{bmatrix} \\quad , \\quad\n",
    "R = E\\left[ r {r}^T \\right] \n",
    "\\qquad\\qquad\n",
    "\\text{Eq. (1-11)}\n",
    "\\end{equation*}\n",
    "\n",
    "where $Z$ referes to the new actual measured value of the states. The $k_m$ index referes to the time segment a measurement is performed by the associated sensor. The noise term $r=N \\left(0, R \\right)$ referes to measurement noise or uncertainty, which comes from mechanism of measurement. It is a sensor-dependent error, provided by the sensor manufacturer, and it usually remains the same throughout the iterative process. Likewise, $R$ is the **sensor noise covariance matrix**.    \n",
    "\n",
    "\n",
    "Whenever a sensor measurement is received from a sensor, it should be mapped into state space to be able to perform prediction step. This mapping is done through matrix $H$. Matrix $H$ is a State Adaption matrix called **measurement matrix**, which is introduced to make the state matrix compatible with the sensor measurement input data. For example, laser sensor measurement includes position data and not velocity measurement. Therefore, for consistancy purposes, we do not change the format of state matrix $X$ and instead, matrix $H$ removes/nullify the velocity elements.  \n",
    "\n",
    "Following our example above, if the measurement is done by a laser sensor, then \n",
    "\n",
    "\\begin{equation*}\n",
    "R = \n",
    "\\begin{bmatrix}\n",
    "{\\sigma_{x}}^2 & 0 \\\\\n",
    "0 & {\\sigma_{y}}^2 \\\\\n",
    "\\end{bmatrix}\n",
    "\\qquad\\qquad\n",
    "\\text{Eq. (1-12)}\n",
    "\\end{equation*}\n",
    "\n",
    "We should often set the off-diagonal elements of the noise covariance matrices to zero, as we do not know the relationship across the states.  \n",
    "\n",
    "\n",
    "<a id=\"section_1-5\"></a>\n",
    "## 1-5. Estimate Kalman Gain  \n",
    "\n",
    "As discussed above, there are two main sources of error â€“ uncertainty â€“ in the system: \n",
    "  - a. Error in estimate. This error refers to previous error; however, for the initial step, we use original error instead.  \n",
    "  - b. Error in data input, i.e. observation in the data.  \n",
    "\n",
    "Kalman gain - KG - applies a relative importance factor â€“ gain â€“ to these two errors. In other words, it quantifies how much we can trust these two errors, in the estimate and in the data. Therefore, after updating the state prediction and state measurement, we let KG decide (calculate) what fraction of the theoretical/predicted and measured values should be contributed into updating the new state. The Kalman gain is a means to assign a weight factor into 'estimation' and 'measured value' (as discussed above). An example of the discrepancy between the measurement and prediction is the error due the delay in measurement process, e.g. by the time we measure a distance of a satellite, it may have moved from the original position. It should be noted that observation provides valuable source of information and we should not simply miss it because of over-confidence in our prediction step. This is another reason why we need to add a regularizer, which in this case it is the **process noise covariance matrix**, $Q$, as introduced above.  \n",
    "\n",
    "\\begin{equation*}\n",
    "\\left( P_{k_{p}} H ^T \\right)\n",
    "{\\left( H P_{k_{p}} H^{T} + R_{k_m} \\right)}^{-1}\n",
    "\\qquad\\qquad\n",
    "\\text{Eq. (1-13)}\n",
    "\\end{equation*}\n",
    "\n",
    "The $k_p$ index referes to the time segment the prediction step is performed.  \n",
    "\n",
    "**Note**:\n",
    "- If in the Kalman filter process, the diagonal elements of **process noise covariance matrix**, $P_{k_{p}}$, become smaller and smaller than the diagonal elements of **sensor noise covariance matrix**, $R$, it means that the Kalman gain pute more emphasis on the predicted values rather than the measured/observed values.  \n",
    "- Reversely, if **sensor noise covariance matrix**, $R$, becomes smaller and smaller in the measurement process - more accurate observation, Kalman gain will put more emphasis on the observation values. \n",
    "\n",
    "\n",
    "\n",
    "## 1-6. Update the State Matrix and Process Error Estimation (Posterior Update)  \n",
    "\n",
    "In the last step before starting the iteration, we combine all the previous calculations to update the posterior, which is our best estimate of the state and its covariance. we update the **state matrix** and the **process error estimation** as per equations below: \n",
    "\n",
    "\\begin{equation*}\n",
    "\\text{New Estimate of State = } \n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "\\text{Predicted State} \n",
    "\\:\n",
    "+\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "\\text{A Portion of the Error between Measurement and Predicted Value, Weighted by the Kalman Gain}\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "X_{k} = X_{k_{p}} + K [Z - H X_{k_{p}}]\n",
    "\\qquad\\qquad\n",
    "\\text{Eq. (1-14)}\n",
    "\\end{equation*}\n",
    "\n",
    " and \n",
    "\n",
    "\\begin{equation*}\n",
    "P_{k} = \\left( I - K H \\right) P_{k_{p}}\n",
    "\\qquad\\qquad\n",
    "\\text{Eq. (1-15)}\n",
    "\\end{equation*}\n",
    "\n",
    "It shoud be noted that by updating the **process error estimation**, we keep track of the error/uncertainty introduced as a part of this KG methodology process. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Extended Kalman Filter and Sensor Fusion  \n",
    "\n",
    "In practice, we may have to deal with updating the states based on the measuremrnts received from multiple sensors, reporting the same type of information (e.g. position and velocity), but in different formats. Therefore, Extended Kalman Filter process is introduced to handle more complex motion and measurement models. For example, to track an object, we can use two sensors, a Radar and a Lidar (or a laser sensor). The measurement-update step depends on the sensor type; Radar measurement involves a nonlinear measurement function, as opposed to the linear function discused above. In this framework, each sensor has its own prediction update scheme and the process continues asynchronously, the same as before, even if we receive several measurements at the same time.  \n",
    "\n",
    "## 2-1. Introducing Nonlinear Terms  \n",
    "\n",
    "The power of Kalman filter is to be able to fuse sensor readings from different sources. Each sensor may work differently, providing different outputs. For example, Lidar sensor can provide rather high-resolution information about position of an object (not velocity). On the other hand, Radar sensor can directly measure and provide the radial velocity of a moving object (using Doppler effect), but at lower spacial resolution as compared to Lidar/laser sensor data. Using extended Kalman filter process, we can fuse the different measurements received from these two sensors, but with different mapping functions. In this section, we take Radar sensor measurement example to derive the extended Kalman filter equations.  \n",
    "\n",
    "The prediction step remains the same for both radar and laser sensors; But for the radar sensor, we need a nonlinear fucntion $h(X)$ to map the states into the sensor measurement space. For radar measurement mapping, $h(X)$ is defined as below:  \n",
    "\n",
    "\\begin{equation*}\n",
    "h \\left( X_{k} \\right) = \n",
    "\\begin{bmatrix}\n",
    "\\rho \\\\\n",
    "\\phi \\\\ \n",
    "\\dot{\\rho}\n",
    "\\end{bmatrix}\n",
    "\\: = \n",
    "\\begin{bmatrix}\n",
    "\\sqrt{{x}^2_{k_{p}} + {y}^2_{k_{p}} } \\\\\n",
    "\\arctan \\left( \\frac{y_{k_{p}}} {x_{k_{p}}}  \\right) \\\\ \n",
    "\\frac{x_{k_{p}} \\dot{x}_{k_{p}} + y_{k_{p}} \\dot{y}_{k_{p}}} {\\sqrt{ {x}^2_{k_{p}} + {y}^2_{k_{p}} }} \\\\\n",
    "\\end{bmatrix}\n",
    ",\n",
    "\\qquad\n",
    "(-\\pi < \\phi < \\pi)\n",
    "\\qquad\\qquad\n",
    "\\text{Eq. (2-1)}\n",
    "\\end{equation*}\n",
    "\n",
    "Since $h(X)$ is a nonlinear function, we cannot apply the Kalman Filter equations, to update the predicted state, X, with new measurements, z. The reason is that nonlinear transformation of Gaussian distribution functions are no longer in the form of Gaussian distribution functions.  \n",
    "\n",
    "A workaround, which is the basis of the Extended Kalman Filter Process, is to approximate it using the linear term of the Taylor expansion of that nonlinear function. Since $h(X)$ is a multi-variable function, we use Multivariate Taylor Series to linearly approximate it as follows: \n",
    "\n",
    "\\begin{equation*}\n",
    "h \\left( X \\right) = \n",
    "h \\left( \\mu \\right) + \n",
    "\\left( X - \\mu \\right)^T D h \\left( \\mu \\right) +\n",
    "\\frac{1}{2!} \\left( X - \\mu \\right)^T D^2 h \\left( \\mu \\right) \\left( X - \\mu \\right) + \\dotso\n",
    "\\qquad\\qquad\n",
    "\\text{Eq. (2-2)}\n",
    "\\end{equation*}\n",
    "\n",
    "where $D h \\left( \\mu \\right)$ and $D^2 h \\left( \\mu \\right)$ are the Jacobian (first order derivative) and the Hessian (second order derivative) matrices, respectively.  \n",
    "\n",
    "In extended Kalman Filter, we ignore non-linear terms, i.e. the terms beyond the Jacobian, as follows: \n",
    "\n",
    "\\begin{equation*}\n",
    "h \\left( X \\right) \\approx \n",
    "h \\left(\\mu \\right) + \\left( X - \\mu \\right)^T D h \\left( \\mu \\right)\n",
    "\\qquad\\qquad\n",
    "\\text{Eq. (2-3)}\n",
    "\\end{equation*}\n",
    "\n",
    "where the Jacobian is defined as follows:\n",
    "\n",
    "\\begin{equation*}\n",
    "D h = \\frac{h\\left( X \\right)}{X} = \n",
    "\\begin{bmatrix}\n",
    "\\frac{\\partial{h_i}}{\\partial{x_j}}\n",
    "\\end{bmatrix}\n",
    "\\: \\approx \\: H_j = \n",
    "\\begin{bmatrix}\n",
    "\\frac{\\partial{h_1}}{\\partial{x_1}} & \\frac{\\partial{h_1}}{\\partial{x_2}} & \\dotsi & \\frac{\\partial{h_1}}{\\partial{x_n}} \\\\ \n",
    "\\frac{\\partial{h_2}}{\\partial{x_1}} & \\frac{\\partial{h_2}}{\\partial{x_2}} & \\dotsi & \\frac{\\partial{h_2}}{\\partial{x_n}} \\\\ \n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "\\frac{\\partial{h_m}}{\\partial{x_1}} & \\frac{\\partial{h_m}}{\\partial{x_2}} & \\dotsi & \\frac{\\partial{h_m}}{\\partial{x_n}} \\\\ \n",
    "\\end{bmatrix}\n",
    "\\qquad\\qquad\n",
    "\\text{Eq. (2-4)}\n",
    "\\end{equation*}\n",
    "\n",
    "Therefore, using Eq. (2-1) we obtain:  \n",
    "\n",
    "\\begin{equation*}\n",
    "\\frac{h\\left( X \\right)}{X} \\approx H_j = \n",
    "\\begin{bmatrix}\n",
    "\\frac{x}{\\sqrt{x^2+y^2}} & \\frac{y}{\\sqrt{x^2+y^2}} & 0 & 0 \\\\ \n",
    "-\\frac{y}{x^2+y^2} & \\frac{x}{x^2+y^2} & 0 & 0 \\\\ \n",
    "\\frac{y \\left( \\dot{x}y - \\dot{y}x \\right) }{\\left( x^2+y^2 \\right)^{3/2}} & \n",
    "\\frac{x \\left( \\dot{y}x - \\dot{x}y \\right) }{\\left( x^2+y^2 \\right)^{3/2}} & \n",
    "\\frac{x}{\\sqrt{x^2+y^2}} & \n",
    "\\frac{y}{\\sqrt{x^2+y^2}} \\\\ \n",
    "\\end{bmatrix}\n",
    "\\qquad\\qquad\n",
    "\\text{Eq. (2-5)}\n",
    "\\end{equation*}\n",
    "\n",
    "## 2-2. Extended Kalman Filter Equations  \n",
    "\n",
    "Extended Kalman filter equations are very similar to Kalman filter equations and they can be stated as follows:  \n",
    "\n",
    "- For state-update (predition) equations:  \n",
    "  - For linear motion models, the regular Kalman filter equations can still be used. In other words, we can still use the same **state transition mmatrix**, $F$.  \n",
    "  - For nonlinear motion models, we need to replace the $f$ matrix with its Jacobian, $F_j$.  \n",
    "- For update-measurement equations:  \n",
    "  - For linear state transformation (e.g. lidar measurement), regular Kalman filter equations can still be used.  \n",
    "  - For nonlinear state transitions (e.g. radar measurement)\n",
    "    - To calculate $P$, $K$, and $S$, $H$ matrix in the Kalman filter will be replaced by the Jacobian matrix $H-j$.  \n",
    "    - To calculate $Y$ and $Z$, the $h$ function is used instead of the $H$ matrix.  \n",
    "\n",
    "<a href=\"Images/EKF-01.jpg\" target=\"_blank\"><img src=\"Images/EKF-01.jpg\" \n",
    "alt=\"Extended Kalman Filter Overview\" width=\"90%\" height=\"90%\" border=\"10\" /></a>  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3- Project Example: Fusing Lidar and Radar Measurement Data \n",
    "\n",
    "The results of the term project are presented here. The [data](/data) provided for this project contains: \n",
    "\n",
    "- Lidar and Radar measurement data \n",
    "- Ground truth values \n",
    "\n",
    "The small piece of program provided uses the received data (lidar and radar measurements) and update the states using EKF equations stated above. To compare the results, in the main function of code we can control which measurement data to be used for estimation. As a result, we ran the program three times using the same data file, however, with different permutation of operational sensors. The comparison of the results shown below reveal that in all the cases studied, utilizing both sensors would give better results as compared to using only one. \n",
    "\n",
    "### Comparison of Position States \n",
    "\n",
    "![Position States](Images/position-states-01.jpg \"Position States\")\n",
    "\n",
    "### Comparison of Mean Errors of Position States \n",
    "\n",
    "![Mean Errors of Position States](Images/position-rmses-01.jpg \"Mean Errors of Position States\")\n",
    "\n",
    "### Comparison of Mean Errors of Velocity States \n",
    "\n",
    "![Mean Errors of Velocity States](Images/velocity-rmses-01.jpg \"Mean Errors of Velocity States\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
